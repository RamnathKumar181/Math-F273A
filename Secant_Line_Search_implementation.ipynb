{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "inVSdrqIVU34",
        "outputId": "1e77bc4c-7f15-4475-99f7-2d93d72d9a5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: 4.000, 2.004, -3.135\n",
            "2: 4.000, 2.009, -3.376\n",
            "3: 4.000, 2.022, -3.844\n",
            "4: 4.000, 2.043, -4.108\n",
            "5: 4.000, 2.081, -4.333\n",
            "6: 4.000, 2.144, -4.495\n",
            "7: 4.000, 2.248, -4.621\n",
            "8: 4.000, 2.425, -4.723\n",
            "9: 4.000, 2.755, -4.820\n",
            "10: 4.000, 2.994, -4.866\n",
            "We hit the norm condition for the problem at iteration: 32\n",
            "The final result after applying the secant method is: 4.000, 3.000, -4.996\n",
            "Objective function at the final point is: 9.102255055716401e-10\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the objective function\n",
        "def objective_function(x):\n",
        "    return (x[0] - 4)**4 + (x[1] - 3)**2 + 4 * (x[2] + 5)**4\n",
        "\n",
        "# Define the gradient of the objective function\n",
        "def gradient(x):\n",
        "    grad = np.zeros_like(x)\n",
        "    grad[0] = 4 * (x[0] - 4)**3\n",
        "    grad[1] = 2 * (x[1] - 3)\n",
        "    grad[2] = 16 * (x[2] + 5)**3\n",
        "    return grad\n",
        "\n",
        "# Steepest Descent to compute the second initial point\n",
        "def steepest_descent(x0, alpha=0.01, epsilon=1e-6):\n",
        "    x_new = x0.copy().astype(np.float64)\n",
        "    g_new = gradient(x_new)\n",
        "    iteration = 0\n",
        "\n",
        "    while np.linalg.norm(g_new) > epsilon and iteration < 1:  # Add limit on iterations\n",
        "        x_new -= alpha * g_new.astype(np.float64)\n",
        "        g_new = gradient(x_new)\n",
        "        iteration += 1\n",
        "\n",
        "    return x_new, g_new\n",
        "\n",
        "# Secant Method for Line Search (two initial points xk and xk-1)\n",
        "def secant_line_search(xk, xk_prev, epsilon=1e-6):\n",
        "    gk = gradient(xk)\n",
        "    gk_prev = gradient(xk_prev)\n",
        "    i=1\n",
        "    while np.linalg.norm(gk) > epsilon:\n",
        "        # Apply secant method step\n",
        "        alpha_k = np.dot(xk - xk_prev, gk - gk_prev) / np.dot(gk - gk_prev, gk - gk_prev)\n",
        "\n",
        "        xk_new = xk - alpha_k * gk\n",
        "\n",
        "        # Update previous values for the next iteration\n",
        "        xk_prev = xk\n",
        "        xk = xk_new\n",
        "        gk_prev = gk\n",
        "        gk = gradient(xk)\n",
        "        if np.linalg.norm(gk) <= epsilon:\n",
        "          print(f\"We hit the norm condition for the problem at iteration: {i}\")\n",
        "          break\n",
        "        if i <= 10:\n",
        "          # Format xk_new to display only 3 decimal places\n",
        "          xk_new_str = ', '.join([f'{val:.3f}' for val in xk_new])\n",
        "          print(f'{i}: {xk_new_str}')\n",
        "        i+=1\n",
        "    return xk\n",
        "\n",
        "# Testing the routine on the provided initial point\n",
        "x_initial = np.array([4, 2, -1])\n",
        "x_second, _ = steepest_descent(x_initial)\n",
        "\n",
        "# Now apply the secant method using the two initial points\n",
        "final_x = secant_line_search(x_initial, x_second)\n",
        "\n",
        "# Print the final result after convergence\n",
        "final_x_str = ', '.join([f'{val:.3f}' for val in final_x])\n",
        "print(\"The final result after applying the secant method is:\", final_x_str)\n",
        "fobj = objective_function(final_x)\n",
        "print(f\"Objective function at the final point is: {fobj}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the objective function\n",
        "def objective_function(x):\n",
        "    return (x[0] - 4)**4 + (x[1] - 3)**2 + 4 * (x[2] + 5)**4\n",
        "\n",
        "# Define the gradient of the objective function\n",
        "def gradient(x):\n",
        "    grad = np.zeros_like(x)\n",
        "    grad[0] = 4 * (x[0] - 4)**3\n",
        "    grad[1] = 2 * (x[1] - 3)\n",
        "    grad[2] = 16 * (x[2] + 5)**3\n",
        "    return grad\n",
        "\n",
        "# Steepest Descent to compute the second initial point\n",
        "def steepest_descent(x0, alpha=0.01, epsilon=1e-6):\n",
        "    x_new = x0.copy().astype(np.float64)\n",
        "    g_new = gradient(x_new)\n",
        "    iteration = 0\n",
        "\n",
        "    while np.linalg.norm(g_new) > epsilon and iteration < 1:  # Add limit on iterations\n",
        "        x_new -= alpha * g_new.astype(np.float64)\n",
        "        g_new = gradient(x_new)\n",
        "        iteration += 1\n",
        "\n",
        "    return x_new, g_new\n",
        "\n",
        "# Secant Method for Line Search (two initial points xk and xk-1)\n",
        "def secant_line_search(xk, xk_prev, epsilon=1e-6):\n",
        "    gk = gradient(xk)\n",
        "    gk_prev = gradient(xk_prev)\n",
        "    i=1\n",
        "    while np.linalg.norm(gk) > epsilon:\n",
        "        # Apply secant method step\n",
        "        alpha_k = np.dot(xk - xk_prev, gk - gk_prev) / np.dot(gk - gk_prev, gk - gk_prev)\n",
        "\n",
        "        xk_new = xk - alpha_k * gk\n",
        "\n",
        "        # Update previous values for the next iteration\n",
        "        xk_prev = xk\n",
        "        xk = xk_new\n",
        "        gk_prev = gk\n",
        "        gk = gradient(xk)\n",
        "        if np.linalg.norm(gk) <= epsilon:\n",
        "          print(f\"We hit the norm condition for the problem at iteration: {i}\")\n",
        "          break\n",
        "        if i <= 10:\n",
        "          # Format xk_new to display only 3 decimal places\n",
        "          xk_new_str = ', '.join([f'{val:.3f}' for val in xk_new])\n",
        "          print(f'{i}: {xk_new_str}')\n",
        "        i+=1\n",
        "    return xk\n",
        "\n",
        "# Testing the routine on the provided initial point\n",
        "x_initial = np.array([-4, 5, 1])\n",
        "x_second, _ = steepest_descent(x_initial)\n",
        "\n",
        "# Now apply the secant method using the two initial points\n",
        "final_x = secant_line_search(x_initial, x_second)\n",
        "\n",
        "# Print the final result after convergence\n",
        "final_x_str = ', '.join([f'{val:.3f}' for val in final_x])\n",
        "print(\"The final result after applying the secant method is:\", final_x_str)\n",
        "fobj = objective_function(final_x)\n",
        "print(f\"Objective function at the final point is: {fobj}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9s-9y2hfcBpi",
        "outputId": "b34ededd-34a6-460c-cff2-f981792ae582"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1: -3.809, 5.000, 0.678\n",
            "2: -2.551, 4.997, -1.257\n",
            "3: -1.415, 4.993, -2.104\n",
            "4: -0.069, 4.985, -2.927\n",
            "5: 0.895, 4.970, -3.437\n",
            "6: 1.661, 4.945, -3.828\n",
            "7: 2.232, 4.902, -4.115\n",
            "8: 2.666, 4.827, -4.333\n",
            "9: 2.993, 4.701, -4.496\n",
            "10: 3.243, 4.493, -4.621\n",
            "We hit the norm condition for the problem at iteration: 37\n",
            "The final result after applying the secant method is: 3.995, 3.000, -4.998\n",
            "Objective function at the final point is: 5.772277268233001e-10\n"
          ]
        }
      ]
    }
  ]
}